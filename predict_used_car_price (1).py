# -*- coding: utf-8 -*-
"""Predict Used Car Price

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12EUNgPfZsiVTn9cQAHhSti-hQSXAE5h-

### Load Data from Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Import Modules"""

from sklearn.linear_model import LinearRegression, Lasso
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.impute import SimpleImputer
import pandas as pd
import matplotlib.pyplot as plt
import plotly.figure_factory as ff
import seaborn as sns
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_percentage_error

"""### Read vehicles CSV file as dataframe."""

df = pd.read_csv('/content/drive/MyDrive/Berkeley/module_11/vehicles.csv')
pd.options.display.float_format = '{:.2f}'.format
df.info()

"""## Check missing values %"""

missing_perc_data = round(df.isnull().sum() * 100 / len(df), 2)
# missing_perc = missing_perc[missing_perc > 0]
print(missing_perc_data.sort_values())

"""
## Data Exploration and visualizations
"""

df['year'] = df['year'].astype('Int64')
df.describe()

"""### Check unique values for categorical columns"""

for col in df.columns.to_list():
  if df[col].dtype == object:
    print(f'Unique values for column {col}: {df[col].unique()}')

"""## Check sample data"""

print(df)

"""## Drop  Field
DataFrame field `id` has no relation to price. So dropping it.*italicized text*
"""

df = df.drop(['id', 'size', 'VIN'], axis=1)

"""## Year Vs Car Price
Below box plot shows clearly that year values range from 1990 to 2022. Alo first quartile value for the year is 2008 and the third quartile value is 2017. Given the large amount of data we can ignore the outliers.
"""

fig = px.histogram(df,
                   x='year',
                   y='price',
                   marginal='box',
                   nbins=20,
                   title='Year Vs Car Counts')
fig.update_layout(bargap=0.1)
fig.update_layout(yaxis_title="Price")
fig.show()

"""## Car price Vs Car Count

Below chart shows that there are some price values which are exceptionally high. Inter quartile ranges:
Q1 : 5900
Q3: 26.48K
Min: 0
Max 3.7 B

"""

fig = px.histogram(df,
                   x='price',
                   marginal='box',
                   color_discrete_sequence=['green', 'grey'],
                   title='Car Price Vs Count')
fig.update_layout(bargap=0.1)
fig.show()

"""## Odometer Vs Car Count
There odometer values which are exceptinally high. It will be good to remove thes values after splitting the data.
"""

fig = px.histogram(df,
                   x='odometer',
                   marginal='box',
                   color_discrete_sequence=['green', 'grey'],
                   title='Odometer Vs Count')
fig.update_layout(bargap=0.1)
fig.show()

"""## Car Price Vs Odometer"""

df_nonull = df.dropna()
df_nonull.head()

plt.figure(figsize=(10, 6))
plt.plot(df_nonull['odometer'], df_nonull['price'], 'o')  # 'o' for scatter plot points
plt.xlabel('Odometer')
plt.ylabel('Price')
plt.title('Car Price vs. Odometer')
plt.grid(True)
plt.show()

# Car price vs odometer correlation
# It clearly shows that as the odmeter goes up the car prices drop.
df_nonull['price'].corr(df_nonull['odometer'])

"""### Split Data"""

X = df.drop('price', axis=1)
y = df['price']
auto_X_train, auto_X_test, auto_y_train, auto_y_test = train_test_split(X, y, test_size=0.2, random_state=42)

auto_X_train.describe()

"""Remove outliers

### Check missing values percentage.
Size column is missing more than 50% values. We can drop it. For other values we will impute the values given the large amount of data it should be fine.
"""

missing_perc = round(auto_X_train.isnull().sum() * 100 / len(df), 2)
# missing_perc = missing_perc[missing_perc > 0]
print(missing_perc.sort_values())

"""## Preatep Train and Test data for cleaning."""

train_data = pd.concat([auto_X_train, auto_y_train], axis=1)
test_data = pd.concat([auto_X_test, auto_y_test], axis=1)

"""## Convert cylinders field to integer."""

def convert_cylinder_to_int(data):
  print(data['cylinders'].unique())
  data['cylinders'] = data['cylinders'].str.replace(' cylinders', '')
  data['cylinders'] = data['cylinders'].str.replace('other', '0')
  print(data['cylinders'].mode())
  data['cylinders'] = data['cylinders'].fillna('6')
  data['cylinders'] = data['cylinders'].astype(int)
  print(data['cylinders'].unique())
  return data
train_data = convert_cylinder_to_int(train_data)
test_data = convert_cylinder_to_int(test_data)

"""## Remove outliers"""

def remove_outlier_using_iqr(df, column):
  q1 = df[column].quantile(.25)
  q3 = df[column].quantile(.75)
  iqr = q3 - q1

  lower_bound = q1 - 1.5 * iqr
  upper_bound = q3 + 1.5 * iqr
  print(iqr, lower_bound, upper_bound)
  df_filtered = df.query(f'{column} >= {lower_bound} and {column} <= {upper_bound}')
  return df_filtered

def remove_outlier_using_zscore(df, column, thres=3):
  z_score = np.abs((df[column] - df[column].mean()) / df[column].std())
  return df[(z_score < thres)]


# df_cleaned = train_data.dropna(subset=['odometer', 'year'])

"""## Remove Outliers in Training Data"""

df_test_cleaned = train_data[train_data['odometer'] > 0]
df_test_cleaned = df_test_cleaned[df_test_cleaned['price'] > 0]
df_test_cleaned = remove_outlier_using_iqr(df_test_cleaned, 'odometer')
df_test_cleaned = remove_outlier_using_iqr(df_test_cleaned, 'price')
df_test_cleaned = remove_outlier_using_iqr(df_test_cleaned, 'year')
X_train_cleaned = df_test_cleaned.drop(columns=['price'])
y_train_cleaned = df_test_cleaned['price']

"""## Remove outliers in Test Data"""

df_train_cleaned = test_data[test_data['odometer'] > 0]
df_train_cleaned = df_train_cleaned[df_train_cleaned['price'] > 0]
df_train_cleaned = remove_outlier_using_iqr(df_train_cleaned, 'odometer')
df_train_cleaned = remove_outlier_using_iqr(df_train_cleaned, 'price')
df_train_cleaned = remove_outlier_using_iqr(df_train_cleaned, 'year')
X_test_cleaned = df_train_cleaned.drop(columns=['price'])
y_test_cleaned = df_train_cleaned['price']

"""## Visualize data after removing outliers"""

fig = px.histogram(df_test_cleaned,
                   x='year',
                   y='price',
                   marginal='box',
                   nbins=20,
                   title='Year Vs Car Price')
fig.update_layout(bargap=0.1)
fig.update_layout(yaxis_title="Price")
fig.show()

fig = px.histogram(df_test_cleaned,
                   x='odometer',
                   y='price',
                   marginal='box',
                   nbins=20,
                   title='Odometer Vs Car Price')
fig.update_layout(yaxis_title="Price")
fig.show()
fig = px.histogram(df_test_cleaned,
                   x='price',
                   marginal='box',
                   nbins=20,
                   title='Car Price Vs Car Counts')
fig.update_layout(bargap=0.1)
fig.show()

"""### Drop and Impute Training dataset."""

df_test_cleaned.describe()

df_test_cleaned.info()

cat_columns = ['transmission', 'drive', 'fuel', 'condition', 'title_status', 'cylinders', 'paint_color', 'type']
for col in cat_columns:
  if df_test_cleaned[col].dtype == object:
    print(f'Unique values for column {col}: {df_test_cleaned[col].unique()}')

"""## Create Processor


"""

numeric_cols = ['year', 'odometer', 'cylinders']
categorical_cols = ['transmission', 'fuel', 'model', 'title_status', 'paint_color', 'drive', 'condition', 'cylinders', 'manufacturer', 'type']


def get_processor(numeric_co, categorical_cols):
  numerical_transformer = SimpleImputer(strategy='median')
  categorical_transformer = Pipeline(steps=[

     ('imputer', SimpleImputer(strategy='most_frequent')),
     ('onehot', OneHotEncoder(handle_unknown='ignore'))])
  preprocessor = ColumnTransformer(
      transformers=[
          ('num', numerical_transformer, numeric_cols),
          ('cat', categorical_transformer, categorical_cols)
      ])
  return preprocessor



"""## Build Regression Model"""

model_regression = Pipeline(steps=[
    ('proc', get_processor(numeric_cols, [])),
    ('reg', LinearRegression())
])

# Train the model
model_regression.fit(X_train_cleaned, y_train_cleaned)

"""Eval Model"""

def get_mse_mae_erros(model_name, train_data, test_data):
  y_pred = model_name.predict(train_data)
  mse = mean_squared_error(test_data, y_pred)
  mape = mean_absolute_percentage_error(test_data, y_pred)
  return y_pred, mse, mape

y_pred_train, mse, mape = get_mse_mae_erros(model_regression, X_train_cleaned, y_train_cleaned)
print(f'Mean Squared Error train data : {mse: .2f}')
print(f'Mean absolute percentage Error train data: {mape: .2f}')

y_pred, mse, mape = get_mse_mae_erros(model_regression, X_test_cleaned, y_test_cleaned)
print(f'Mean Squared Error test data : {mse: .2f}')
print(f'Mean absolute percentage Error test data: {mape: .2f}')

plt.figure(figsize=(12, 6))
plt.plot(range(len(y_test_cleaned)), y_test_cleaned, label='Actual', color='blue', marker='o', linestyle='-', linewidth=2)
plt.plot(range(len(y_pred)), y_pred, label='Predicted', color='orange', marker='x', linestyle='--', linewidth=2, alpha=0.2)
plt.xlabel('Data Point Index')
plt.ylabel('Value')
plt.title('Comparison of Actual and Predicted Values')
plt.legend()
plt.grid(True)
plt.show()

"""Train numerical and Categorical Linear Regression model"""

model_regression_more_cols = Pipeline(steps=[
    ('proc', get_processor(numeric_cols, ['transmission', 'fuel', 'model', 'title_status', 'paint_color',])),
    ('reg', LinearRegression())
])

# Train the model
model_regression_more_cols.fit(X_train_cleaned, y_train_cleaned)

y_pred_train, mse, mape = get_mse_mae_erros(model_regression_more_cols, X_train_cleaned, y_train_cleaned)
print(f'Mean Squared Error train data : {mse: .2f}')
print(f'Mean absolute percentage Error train data: {mape: .2f}')

y_pred, mse, mape = get_mse_mae_erros(model_regression_more_cols, X_test_cleaned, y_test_cleaned)
print(f'Mean Squared Error test data : {mse: .2f}')
print(f'Mean absolute percentage Error test data: {mape: .2f}')

plt.figure(figsize=(12, 6))
plt.plot(range(len(y_test_cleaned)), y_test_cleaned, label='Actual', color='blue', marker='o', linestyle='-', linewidth=2)
plt.plot(range(len(y_pred)), y_pred, label='Predicted', color='orange', marker='x', linestyle='--', linewidth=2, alpha=0.1)
plt.xlabel('Data Point Index')
plt.ylabel('Value')
plt.title('Comparison of Actual and Predicted Values')
plt.legend()
plt.grid(True)
plt.show()

"""## Lasso regression"""

numeric_cols = ['year', 'odometer', 'cylinders']
categorical_cols = ['transmission', 'fuel', 'model', 'title_status',
                    'paint_color', 'drive', 'condition', 'cylinders',
                    'manufacturer', 'type']

categorical_cols = []
numeric_transformer = StandardScaler()

# Preprocessing for categorical data: One-hot encoding
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Combine preprocessing for numeric and categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_cols),
        ('cat', categorical_transformer, categorical_cols)
    ]
)

# Create a pipeline that first preprocesses the data and then applies Lasso regression
lasso_pipeline = Pipeline(steps=[
    ('preprocessing', preprocessor),
    ('lasso', Lasso(alpha=1.0))  # You can tune the alpha parameter for regularization strength
])

# Fit the pipeline to the training data
lasso_pipeline.fit(X_train_cleaned, y_train_cleaned)

# Predict on the train set
y_pred = lasso_pipeline.predict(X_train_cleaned)

# Evaluate the model on train
mse = mean_squared_error(y_train_cleaned, y_pred)
rmse = np.sqrt(mse)

print(f"Root Mean Squared Error (RMSE) train data: {rmse}")

# Predict on the test set
y_pred = lasso_pipeline.predict(X_test_cleaned)
# Evaluate the model on test
mse = mean_squared_error(y_test_cleaned, y_pred)
rmse = np.sqrt(mse)

print(f"Root Mean Squared Error (RMSE) test data: {rmse}")

# Check the coefficients of the Lasso model
lasso_model = lasso_pipeline.named_steps['lasso']
for i, j in zip(
      lasso_pipeline[:-1].get_feature_names_out(),
      lasso_pipeline[-1].coef_):
  print(i, j)